# PGPM - Synthetic Signal Generation

**Version 3.6**

## Description
This repository contains _Python_ code that can be used to draw signals from the piecewise Gaussian process model described in DSP2025 paper _A Piecewise Gaussian Process Model for Evaluating Training and Performance of Time-Series Pipelines_. The code here is slightly more general than that used to present the paper, but parameter settings can be adjusted to reproduce the same results (to within finding the seed for the PRNG).

The signal model was initially used to develop both the architecture and training strategy for deep networks that consumed time-series and provided a dense labelling of the temporal axis according to the nature of the activity occurring within an interval of time. The signal looks simple, but a full statistical model is non-trivial. For example, as (discrete) time progresses, the components that may be selected under the sampling-without-replacement option are dependent on those selected earlier in time; the same is true for the intervals of time over which the components will be active. In a sense, the model displays a (model-dependent) temporal causality, and is not trivially Markovian.

![An example of one signal, together with its ground truth, constructed through sequential sampling. The ground truth can be represented in different ways: by a single channel containing zero where there is no active shape, or integer values of 1 to 5 for the samples where the relevant shape is active. The other representation is to incorporate 6 channels -- one for each class -- which contain values of zero or 1, 1 at the sample locations (intervals) where an appropriate class is present. Ground truth in this way, by assumption, would only allow one channel to be "hot" at any particular time sample in the ground truth. However, for a network that is uncertain of the nature of the signal at any point in time, we might expect multiple channels to be non-zero.](./Figures/signalshapedemo.svg)


The material in this repo focusses on interpreting and conveying the nature of this signal model. We have found the signals useful in a number of projects in which the goal is to test time-series labelling. It should be seen as a providing "test signals", similar to those used in electrical engineering to characterise the input/output mappings of engineered systems. Unlike many techniques that depend on impulse responses, input sine-waves, or noise sources, the form of the discrete-time waveforms generated by this code are of finite temporal support. They may be of particular use in:

 - Regression testing (in a software engineering sense).

 - Pre-training and hyperparameter tuning of deep networks for time-series classification or dense temporal segmentation.

 - Testing of interpretability techniques for whole (temporal)-axis signal classifiers, since ground truth can be specified.

 - Systematic studies of noise-robustness for classification, dense segmentation techniques or parameter estimation.

## Demo Notebook
The _Jupyter_ notebook entitled ```Demo``` reproduces many of the graphs used in the paper (again, seeds are not recorded or set for the PRNG, but you'll get similar results).

### Statistical Model
The model is simply described as somewhat similar in spirit to a Gaussian process. For a discrete-time signal, indexed by time-linked variable, $k$,
 
$s(k) ~ f_s(k|\mathcal{M}), k= 0,1,2,..K-1$
 
and the distribution for additive white-noise is:
$f_s(k) = \mathcal{N}(\mu(k); \sigma)$
 
with coloured noise being:
$f_s(k) = \mathcal{N}(\mu(k); \Sigma)$
where $\Sigma$ is the covariance matrix of additive coloured noise. For example, such noise can be generated by a first-order autoregressive process, or by running a white noise through a band-pass filter.
 

### Model $\mathcal{M}$
The model of individual temporal structures reflects non-overlapping waveforms of finite temporal support, each taking a different shape. Each waveform is characterised by a small number of parameters, such as amplitude, duration, and frequency. Waveform shapes are similar in spirit to 2D shapes, but the 'shape' in this case refers to the temporal evolution (local autocorrelation structure) of the signal, and these are restricted to a small number of forms:
  - a one-sided ramp,
  - a symmetric up/down ramp,
  - a square wave and
  - two oscillatory waves
 
Those familiar with _signal generators_ will recognise the obvious parallels, where characteristic temporal shapes, such as these, are used as 'test signals' to measure the fidelity of a signal processing system.
 
![In addition to semantic temporal segmentation, the signals are also given one of two classes, which apply to each whole signal, but where the class differences are localised. The classes are distinguished by having two different frequency distributions associated with the cosine waveform; these 2 classes can have varying degrees of separability, and are easily defined through ground truth. The classes also have different amplitude distributions for the square wave (not shown), allowing the development of techniques to probe saliency measures, and also approaches to training classifiers which are specific to, or ignorant of, amplitude distributions.](./Figures/CosFreqDist.svg)
 
### Noise Model
So far, the PGPM is based around a trivial noise model. It is easily converted into one with a non-trivial covariance structure, say, by running white-noise into a linear band-pass filter and adding the filtered noise to the noise-free signal.
 
### Pseudo-Code for Signal Generation
The signal generation process can be summarised in pseudo-code, which is presented in the DSP 2025 Conference paper (Anil A Bharath, _A Piecewise Gaussian Process Model for Evaluating Training and Performance of Time-Series Pipelines_, 2025.)

## TO DO

 0. Include dense segmentation training

 1. Add in baseline drift modelling/trends
    
 2. Turn shape waveforms into generalised functions

 3. Include multiplicative gain variations
 
## Training Notebook for Dense, Multiclass Signal Segmentation

The notebook `Train.ipynb` contains code to train a signal segmentation network, and provides a demonstration of the results of inference. One would not expect perfect segmentation results, particularly in signal samples where there are low signal shape amplitudes for one or more of the shapes, and in the presence of non-negligible noise.

![A demonstration of the output of a trained signal classification network, illustrating clear demonstrations of correct classification, but also showing instances where the network is not _perfectly_ sure of the class. This is what we want, however, as some shapes could be truly ambiguous, based on a combination of amplitude levels and noise.](sigsegdemo.svg)

### Logging of Train/Validation Losses
This training code contains two different types of logging, one for Tensorboard (TB) and the other for Weights and Biases (WandB).  The TB logging is all held locally in the `runs` directory, whilst the WandB logging requires an account and API key for the WandB website. It seems that TB works better at visualising traces for train and val simultaneously without requiring manual fiddling of the plots, so this is recommended.

To visualise using TB, you need to also have installed `tensorboard`, which can be installed using `pip`; it is not run from the notebook, but rather the command line:

`tensorboard --logdir=runs`

then, point a browser at `localhost` on port 6006:

`http://localhost:6006/`

and your training runs should appear.


## Directory Structure

PGPM/
├── Demo.ipynb                # Notebook that demonstrates the PGPM signal model characteristics
├── Train.ipynb               # Training notebook for signal segmentation
├── Figures/                  # Figure directory for generated figures
├── runs/                     # Directory for TensorBoard logs (local logging)
├── savedmodels/              # Directory for saved models after training
├── model/                    # Directory containing the model definition
│   └── model.py              # Model architecture and related code
│   └── unet1parts.py         # Model architecture and related code
├── datagenerator/            # Directory containing data generator classes
│   └── dataclass.py          # Dataloader class for signals
│   └── DG.py                 # Main code for the 
├── utils/                    # Directory for utility functions
│   └── utils.py              # Code for visualizing signal classes and samples
├── training/                 # Directory for training-related scripts and configurations
│   └── train_utils.py        # Helper functions for training
├── README.md                 # Project documentation
└── pgpm.yml                  # Conda environment configuration file


## Installation
This is a relatively undemanding installation. The model itself makes use of ``PyTorch`` because the generator can be used in a manner similar to a dataloader, where files would be loaded from disk. However, signals are easily generated on the fly.
Recommended installation of ```Python``` packages is via conda or miniconda:

conda env create --file pgpm.yml

---
